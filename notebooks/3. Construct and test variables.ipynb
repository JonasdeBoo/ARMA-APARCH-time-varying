{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Construct and test variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is created to merge all relevant DataFrames for each company, and in order to retrieve the relevant daily data. These daily variables are then tested in order to satisfy the constraints the AR-GARCH-X model imposes on the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Load data and packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Load packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the relevant packages needed for the main analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os, sys\n",
    "from datetime import datetime\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Load data that returns tweets\n",
    "sys.path.insert(0, os.path.abspath('C:\\\\Users\\\\Jonas\\\\PycharmProjects\\\\TwitterSentimentGARCH2021\\\\Code\\\\Variable construction and tests'))\n",
    "from variableconstruction import VariableSelection\n",
    "\n",
    "# Get path with the Time-varying specification function\n",
    "sys.path.insert(0, os.path.abspath(r'C:\\Users\\Jonas\\PycharmProjects\\TwitterSentimentGARCH2021\\Code\\GARCH model\\tvGARCH models'))\n",
    "from helper_func import regimeshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Colors for plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct color code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['seagreen', 'mediumaquamarine', 'steelblue', 'cornflowerblue', 'navy', 'black']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give the location of all Data objects, as some of the data is company specific, also load the company names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load company name data\n",
    "data_loc = r'C:\\Users\\Jonas\\Documents\\Data'\n",
    "file_name_comp = '\\company_ticker_list_all.xlsx'\n",
    "\n",
    "df_comp_names = pd.read_excel(data_loc + file_name_comp)\n",
    "\n",
    "# Specify return data location\n",
    "return_loc = r'C:\\Users\\Jonas\\Documents\\Data\\Returns'\n",
    "\n",
    "# Specify sentiment data location\n",
    "sentiment_loc = r'C:\\Users\\Jonas\\Documents\\Data\\Sentiment'\n",
    "\n",
    "# Load control variable data\n",
    "store_loc = r'C:\\Users\\Jonas\\Documents\\Data\\Control variables'\n",
    "file_VIX = '\\\\VIX.csv'\n",
    "file_ted = '\\\\TEDRATE.csv'\n",
    "df_vix = pd.read_csv(store_loc+file_VIX).set_index('Date')\n",
    "df_ted = pd.read_csv(store_loc+file_ted).set_index('DATE')\n",
    "\n",
    "df_control = pd.merge(df_vix, df_ted, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Convert values in TEDRATE column to floats, remove '.' and then interpolate\n",
    "df_control.TEDRATE = df_control.TEDRATE.replace('.', None)\n",
    "df_control.TEDRATE = df_control.TEDRATE.astype(float)\n",
    "df_control.TEDRATE = df_control.TEDRATE.interpolate()\n",
    "\n",
    "# Reset index\n",
    "df_control = df_control.reset_index()\n",
    "\n",
    "# Rename Close to VIX\n",
    "df_control = df_control.rename(columns={'Close':'VIX'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Determine relevant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use first entry to inspect the columns of the sentiment and return data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first entry of return data and print column names\n",
    "df_returns = pd.read_csv(return_loc + f'//{df_comp_names.Symbol.iloc[0]}.csv')\n",
    "print(df_returns.columns)\n",
    "\n",
    "# Load first entry of sentimnent data and print column names\n",
    "df_sentiment = pd.read_csv(sentiment_loc + f'//sentiment {df_comp_names.Company.iloc[0]}.csv')\n",
    "print(df_sentiment.columns)\n",
    "\n",
    "# Also inspect control DataFrame columns\n",
    "print(df_control.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the print statement, keep columns that might hold valuable information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set columns that we want to keep: returns\n",
    "returns_cols = ['returns', 'Volume']\n",
    "return_date_col = 'Date'\n",
    "\n",
    "# Set columns that we want to keep: sentiment\n",
    "sentiment_cols = ['sentiment', 'n_interactions', 'n_tweets']\n",
    "sentiment_date_col = 'date'\n",
    "\n",
    "# Set columns that we want to keep: control variables\n",
    "control_cols = ['VIX', 'TEDRATE']\n",
    "control_date_col = 'index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 Determine store location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine location where DataFrames can be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_loc = r'C:\\Users\\Jonas\\Documents\\Data\\Total_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, inspect the data before it is tested, and make some plots\n",
    "\n",
    "First, make plot of the control variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get possible values of h\n",
    "h_vals = [10, 25]\n",
    "styles = ['--', ':']\n",
    "colors = ['black', 'cornflowerblue']\n",
    "\n",
    "# Create DataFrame indicating the regime, using the regimeshift function\n",
    "df_regime = pd.DataFrame()\n",
    "df_regime['date'] = df_control['index'].values\n",
    "for col in control_cols:\n",
    "    df_regime[col] = (df_control[col] - df_control[col].mean()) / df_control[col].std()\n",
    "\n",
    "for h in h_vals:\n",
    "    df_regime[f'{h}'] = regimeshift(df_regime, control_cols, h, [0, 0])\n",
    "\n",
    "# Plot control variables & regime\n",
    "fig = plt.figure(figsize=(18,10), tight_layout=True)\n",
    "spec = gridspec.GridSpec(ncols=8, nrows=2, figure=fig)\n",
    "\n",
    "# Get subplots\n",
    "ax1 = fig.add_subplot(spec[0,0:4])\n",
    "ax2 = fig.add_subplot(spec[0,4:8])\n",
    "ax3 = fig.add_subplot(spec[1,2:6])\n",
    "axs = [ax1, ax2, ax3]\n",
    "    \n",
    "first_date, last_date = df_control['index'][0], df_control['index'][len(df_control)-1]\n",
    "n = 250  # keeps every 250th label (around 1 year)\n",
    "\n",
    "for j in range(len(axs)):\n",
    "    # plot something differenct on both axes\n",
    "    if j == 0:\n",
    "        axs[j].plot(df_control['index'], df_control.VIX, c='black', linestyle='-.')\n",
    "        axs[j].fill_between(df_control['index'], 0, max(df_control.VIX), where= df_control.VIX > np.mean(df_control.VIX), facecolor='cornflowerblue', alpha=0.25)\n",
    "        axs[j].set_title(f'CBOE Volatility Index')\n",
    "    elif j == 1:\n",
    "        axs[j].plot(df_control['index'], df_control.TEDRATE, c='black', linestyle='-.')\n",
    "        axs[j].fill_between(df_control['index'], 0, max(df_control.TEDRATE), where= df_control.TEDRATE > np.mean(df_control.TEDRATE), facecolor='cornflowerblue', alpha=0.25)\n",
    "        axs[j].set_title(f'Treasury-EuroDollar rate Spread')\n",
    "    else:\n",
    "        for h, ls, color in zip(h_vals, styles, colors):\n",
    "            axs[j].plot(df_regime['date'], df_regime[f'{h}'], linestyle=ls, color=color, label = f'Transition function values, h = {h}')\n",
    "            axs[j].legend(loc='upper left')\n",
    "            \n",
    "    # Set title and xticklabels\n",
    "    axs[j].set_xticks(axs[j].get_xticks()[::n])\n",
    "        \n",
    "    axs[j].tick_params(axis='x', labelrotation = 45)\n",
    "    \n",
    "plt.tight_layout()\n",
    "    \n",
    "# Store figures as PNG\n",
    "fig.savefig(os.path.join(store_loc, f'control_variables.png'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Perform analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Calculate total df's and store them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section exploits the class `VariableSelection` to merge all DataFrames and perform tests to check if the variables satisfy all constraints needed to serve as input for a GARCH model. This code checks out whether the variables do not have a unit-root with help of the Dickey-Fuller test. If a unit root is present, the percentual difference of a variable is then tested for a unit-root, if this variable does not have a unit root, the percentual difference will be taken instead of the variable itself, the percentual difference is in turn standardized as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_comp_names)):    \n",
    "    company_name = df_comp_names.iloc[i]['Company']\n",
    "    ticker = df_comp_names.iloc[i]['Symbol']\n",
    "    \n",
    "    # Get df_returns\n",
    "    returns_name = f'//{ticker}.csv'\n",
    "    df_returns = pd.read_csv(return_loc + returns_name)   \n",
    "    df_returns['returns'] = 100 * np.log(df_returns.Close).diff() # Calculate returns in percentages\n",
    "    df_returns = df_returns.dropna()\n",
    "\n",
    "    # Get df_sentiment\n",
    "    sentiment_name = f'//sentiment {company_name}.csv'   \n",
    "    df_sentiment = pd.read_csv(sentiment_loc + sentiment_name)\n",
    "    \n",
    "    # Shrink df's to contain only columns that are of interest\n",
    "    df_returns = df_returns[[return_date_col] + returns_cols]\n",
    "    df_sentiment = df_sentiment[[sentiment_date_col] + sentiment_cols]\n",
    "    df_control = df_control[[control_date_col] + control_cols]\n",
    "    \n",
    "    # Use VariableSelection to find total DataFrame\n",
    "    select_object = VariableSelection(df_returns=df_returns, \n",
    "                                      df_sentiment=df_sentiment, \n",
    "                                      df_control=df_control, \n",
    "                                      date_col_ret=return_date_col, \n",
    "                                      date_col_sent=sentiment_date_col, \n",
    "                                      date_col_control=control_date_col, \n",
    "                                      return_cols=returns_cols, \n",
    "                                      sentiment_cols=sentiment_cols, \n",
    "                                      control_cols=control_cols)\n",
    "    \n",
    "    df_total = select_object.test_stationarity()\n",
    "    \n",
    "    # Delete too old data\n",
    "    if len(df_total) > 2685:\n",
    "        date = '2011-01-03'\n",
    "        indice = df_total[df_total.date == date].index.tolist()[0]\n",
    "        df_total = df_total[indice:]\n",
    "    \n",
    "    # Store df_total as an .csv file\n",
    "    store_name = f'\\\\total data {company_name}.csv'    \n",
    "    df_total.to_csv(store_loc + store_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Construct correlation matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more insights into how the variables are related, construct and print correlation matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#p = pval.applymap(lambda x: ''.join(['*' for t in [0.01,0.05,0.1] if x<=t]))\n",
    "#rho.round(2).astype(str) + p\n",
    "\n",
    "for company in df_comp_names['Company']:  \n",
    "    # Get df_total\n",
    "    store_name = f'\\\\total data {company}.csv'  \n",
    "    df_total = pd.read_csv(store_loc + store_name)\n",
    "    \n",
    "    # Drop NA (Can also be done in analysis)\n",
    "    df_total = df_total.dropna()\n",
    "    print(f\"Correlation matrix of {company}\")\n",
    "    rho = df_total[df_total.columns[df_total.columns != 'date']].corr()\n",
    "    pval = df_total[df_total.columns[df_total.columns != 'date']].corr(method = lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "    \n",
    "    p = pval.applymap(lambda x: ''.join(['*' for t in [0.01,0.05,0.1] if x<=t]))\n",
    "    rho = rho.round(3).astype(str) + p\n",
    "    display(rho)\n",
    "    rho.to_csv(store_loc + f'//correlation of {company}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3. Create descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out descriptive statistics of the variables included in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_describe = pd.DataFrame()\n",
    "for company, ticker in zip(df_comp_names['Company'], df_comp_names.Symbol):  \n",
    "    # Get df_total\n",
    "    store_name = f'\\\\total data {company}.csv'  \n",
    "    df_total = pd.read_csv(store_loc + store_name)\n",
    "    \n",
    "    df_total[f'${ticker}'] = df_total['returns']\n",
    "    \n",
    "    # Concatenate all company DataFrames\n",
    "    df_describe = pd.concat([df_describe, df_total[[f'${ticker}', 'VIX', 'TEDRATE']].describe()], axis=1)\n",
    "    \n",
    "# Remove duplicate columns  \n",
    "df_describe = df_describe.loc[:,~df_describe.columns.duplicated()]\n",
    "display(df_describe)\n",
    "df_describe.to_csv(store_loc + f'\\\\descriptive stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
