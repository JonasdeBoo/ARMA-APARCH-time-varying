{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sentiment analysis and aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This template is used to get sentiment scores using VADER sentiment of all tweets per company. When calculating the VADER sentiment of each, they will be aggregated via the Fisher sentiment score to calculate the daily sentiment based on the number of likes, retweets, replies and quotes. Later, plots of the daily sentiment, daily number of interactions and daily number of tweets per company are returned to provide some intuition about the behaviour of these metrics.\n",
    "\n",
    "This Jupyter Notebook provides the opportunity to quickly inspect and test daily sentiment scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Load packages and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class loads all relevant packages and dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Load packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import all classes necessary for the running of this files. Then import the relevant classes from the Python `thesis_code` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Load data that returns tweets\n",
    "sys.path.insert(0, os.path.abspath('C:\\\\Users\\\\Jonas\\\\PycharmProjects\\\\TwitterSentimentGARCH2021\\\\Code\\\\Sentiment analysis and aggregation'))\n",
    "from sentanalysis import TwitterSentimentAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Construct colors for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct self-constructed colormap that will be used throughout this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['seagreen', 'mediumaquamarine', 'steelblue', 'cornflowerblue', 'navy', 'black']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3.1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, load the data with company names. Also specify the storage location where the sentiment data must be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify location of data + file name and location of storage\n",
    "data_loc = r'C:\\Users\\Jonas\\Documents\\Data'\n",
    "file_name_comp = '\\company_ticker_list_all.xlsx'\n",
    "\n",
    "# Specify location where daily sentiment scores must be stored\n",
    "store_loc = r'C:\\Users\\Jonas\\Documents\\Data\\Sentiment'\n",
    "\n",
    "# Access company names DataFrame\n",
    "df_comp_names = pd.read_excel(data_loc + file_name_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3.2. Load return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load return data to get dates of trading days in the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a dictionary to store all daily returns in\n",
    "dict_returns = {}\n",
    "\n",
    "for tckr in df_comp_names.Symbol:\n",
    "    returns_loc = f'C:\\\\Users\\\\Jonas\\\\Documents\\\\Data\\\\Returns\\\\{tckr}.csv'\n",
    "    dict_returns[f'returns {tckr}'] = pd.read_csv(returns_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Analysis of tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section performs the main calculations and analysis of the Twitter data. The returned daily sentiment data is stored in a seperate folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find tweets per company, all stored in one folder\n",
    "for i in range(len(df_comp_names)):\n",
    "    company_name = df_comp_names.iloc[i]['Company']\n",
    "\n",
    "    tweets_data_loc = f'C:\\\\Users\\\\Jonas\\\\Documents\\\\Data\\\\Tweets\\\\tweets {company_name}.csv'\n",
    "    \n",
    "    # find tweets of current company, and store as df_tweets\n",
    "    df_tweets = pd.read_csv(tweets_data_loc)\n",
    "    print(df_tweets.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Load and analyse tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tweets, retrieved via the Notebook `data_collection` (*consult this Notebook for reference*). Then, create a sentiment analysis object for every company specific list of tweets. The class `TwitterSentimentAnalysis` has several attributes, where public metrics are seperated, dates are splitted into time and date columns, to aggregate the tweets per date. Then, the VADER sentiment lexicon is exploited to calculated the sentiment score of each tweets of the dataset. The aggregation of the tweets is done via the Fisher score, which is calculated on a daily basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find tweets per company, all stored in one folder\n",
    "for i in range(len(df_comp_names)):\n",
    "    company_name = df_comp_names.iloc[i]['Company']\n",
    "\n",
    "    tweets_data_loc = f'C:\\\\Users\\\\Jonas\\\\Documents\\\\Data\\\\Tweets\\\\tweets {company_name}.csv'\n",
    "    \n",
    "    # find tweets of current company, and store as df_tweets\n",
    "    df_tweets = pd.read_csv(tweets_data_loc)\n",
    "    \n",
    "    # Sort tweets in descending order based on date and time\n",
    "    df_tweets = df_tweets.sort_values(by=['created_at']).reset_index(drop=True)\n",
    "    \n",
    "    # Get unique trading days of company i\n",
    "    trading_days = dict_returns[f'returns {df_comp_names.Symbol.iloc[i]}'].Date.unique().tolist()\n",
    "    unique_trading_days = []\n",
    "    for trading_day in trading_days:\n",
    "        unique_trading_days.append((datetime.strptime(trading_day, '%Y-%m-%d')).date())\n",
    "\n",
    "    # Construct for every class a sentiment object\n",
    "    sentiment_obj = TwitterSentimentAnalysis(df_tweets, 'text', 'public_metrics', 'created_at', unique_trading_days)\n",
    "    \n",
    "    # Calculate daily sentiment based on the calculate_daily_sent method of the sentiment_obj. This dataframe also \n",
    "    # contains the number of daily interactions and the number of daily tweets, the other quantitative sentiment metrics.\n",
    "    df_daily_sent = sentiment_obj.calculate_daily_sent()\n",
    "    \n",
    "    # Save daily sentiment dataframe as csv\n",
    "    store_name = f'\\sentiment {company_name}.csv'    \n",
    "    df_daily_sent.to_csv(store_loc + store_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Display sentiment scores and quantititave metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will display daily sentiment scores, the number of tweets and the number of daily interactions. These are returned both as describtion DataFrames and in plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find tweets per company, all stored in one folder\n",
    "for i in range(len(df_comp_names)):\n",
    "    company_name = df_comp_names.iloc[i]['Company']\n",
    "   \n",
    "    # Save daily sentiment dataframe as csv\n",
    "    store_name = f'\\sentiment {company_name}.csv'    \n",
    "    df_daily = pd.read_csv(store_loc + store_name)\n",
    "    display(df_daily.describe())\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize = (20,4), nrows = 1, ncols = 3)\n",
    "    \n",
    "    first_date, last_date = df_daily.date.iloc[0], df_daily.date.iloc[-1]\n",
    "    n = 150  # keeps every 30th label (around 1 month)\n",
    "\n",
    "    for j in range(len(axs)):\n",
    "        columns = df_daily.columns\n",
    "        # If the metric is not sentiment score, plot the log change of the metrics (number of interactions and number of tweets)\n",
    "        if j != 0:\n",
    "            axs[j].plot(df_daily.date, df_daily[columns[j+3]], c=colors[j])\n",
    "        else:\n",
    "            axs[j].plot(df_daily.date, df_daily.sentiment, c=colors[j])\n",
    "        \n",
    "        # Set title and xticklabels\n",
    "        axs[j].set_title(f'Company: {company_name}' + '\\n' f'{columns[j+3]} between {first_date} and {last_date}')\n",
    "        axs[j].set_xticks(axs[j].get_xticks()[::n])\n",
    "        \n",
    "        axs[j].tick_params(axis='x', labelrotation = 45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Store figures as PNG\n",
    "    fig.savefig(os.path.join(store_loc, f'sentiment metrics {company_name}'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
