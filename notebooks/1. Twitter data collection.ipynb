{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Twitter data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This template illustrates the use of `data_collection`. In this template the Twitter data, filtered on tweets containing ESG words are selected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load relevant data, packages and set user input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Loading packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load relevant python packages and relevant classes from the python library, containing all classes used for this research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "# Load class that returns tweets\n",
    "sys.path.insert(0, os.path.abspath('C:\\\\Users\\\\jdeboo\\\\PycharmProjects\\\\TwitterSentimentGARCH2021\\\\Code\\\\Data collection'))\n",
    "from main_api_code import CollectTwitterData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Load Company identifier data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datafile containing names and Ticker symbols of the 50 largest companies of the S&P500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = r'C:\\Users\\Jonas\\Documents\\Data\\company_ticker_list_all.xlsx'\n",
    "df = pd.read_excel(data_loc)\n",
    "\n",
    "# Quickly leave out Facebook\n",
    "df = df[df.Symbol != 'FB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Create negation filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each company has own negation filter, to satisfy query limits set by Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negation = pd.DataFrame(columns = df['Company'].values)\n",
    "\n",
    "negation_apple = '(-fruit - eat -\\\"apple  music\\\" -\\\"green apple\\\" -apple.news -\\\"apple watch\\\" -music.apple -apps.apple -\\\"red apple\\\" -\\\"apple juice\\\" -IOS -\\\"apple tea\\\" -\\\"apple cake\\\" -\\\"apple cider\\\" -playing -games)'\n",
    "negation_amazon = '(-\\\"the amazon\\\" -\\\"amzn.to\\\" -\\\"amazon.com\\\" -\\\"brazilian amazon\\\" -\"rainforest\" -\"https://www.amazon\" -\"amazon.in\" -\"https://featurepoints.com\" -\\\"free gift cards\\\")'\n",
    "negation_chevron = None\n",
    "negation_cola = None\n",
    "negation_exxon = None\n",
    "negation_macd = None\n",
    "negation_microsoft = '(-\\\"microsoft office\\\" -\\\"microsoft teams\\\")'\n",
    "negation_netflix = '(-\\\"watch netflix\\\" -\\\"watching netflix\\\" -\\\"netflix series\\\" -\\\"alteredcarbon\\\" -\\\"altered carbon\\\")'\n",
    "negation_nike = '(-\\\"green nike\\\" -\\\"nike air\\\" -\\\"air max\\\")'\n",
    "negation_salesforce = None\n",
    "negation_tesla = None\n",
    "negation_walmart = None\n",
    "\n",
    "negation_row = [negation_apple, negation_amazon, negation_chevron, negation_cola, negation_exxon, \n",
    "                negation_google, negation_macd, negation_microsoft, negation_netflix, negation_nike, negation_salesforce,\n",
    "                negation_tesla, negation_walmart]\n",
    "\n",
    "df_negation.loc[len(df_negation)] = negation_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4. Set file location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set location where to store extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_loc = 'C:\\\\Users\\\\Jonas\\\\Documents\\\\Data\\\\Tweets\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5. Set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters such as the maximum number of pages, and start date.\n",
    "\n",
    "*Note*: dates should be included as a string in the format \"YYYYMMDDHHmm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "n_pages = 1000\n",
    "max_results = 500\n",
    "start_date = '2011-01-01T00:00:00Z'\n",
    "critical_date = '2011-01-05T00:00:00Z'\n",
    "end_date = '2021-08-31T12:00:00Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Get tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store tweets as a DataFrame in a dictionary where the key matches the normal company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set counter\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find tweets for every company in the company DataFrame `df`. Use per company the company specific negation dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(8, len(df)):\n",
    "    # Set company attributes\n",
    "    company_name = df.iloc[i]['Company']\n",
    "    off_comp_name = df.iloc[i]['Official Company Name'] \n",
    "    ticker = df.iloc[i]['Symbol']\n",
    "    \n",
    "    # Construct attribute to collect tweets\n",
    "    tweet_obj = CollectTwitterData(n_pages, max_results, start_date, end_date, critical_date, company_name, off_comp_name, ticker, counter, df_negation[company_name][0])\n",
    "    tweets, counter = tweet_obj.get_tweets()\n",
    "    \n",
    "    # unpack public_metrics and discard public_metrics column\n",
    "    tweets = tweets.reset_index(drop=True)\n",
    "    tweets[['like_count', 'quote_count', 'reply_count', 'retweet_count']] = pd.DataFrame.from_records(tweets.public_metrics.dropna().tolist())\n",
    "    tweets.drop(['public_metrics'], axis=1)\n",
    "        \n",
    "    file_name = f'tweets {company_name}.csv'   \n",
    "    tweets.to_csv(store_loc+file_name, header=True)\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "-------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
